# Spark程序的调度过程

1. 用户使用spark-submit命令提交一个Spark应用程序。
2. spark-submit 在同一节点（客户端模式）或集群（集群模式）上启动驱动老蚌生珠，并调用由用户指定的main方法。
3. 驱动进程联系集群管理器，根据提供的配置参数来请求启动执行进程JVM所需的资源。
4. 集群管理器在工作机节点上启动执行进程JVM
5. 驱动进程扫描用户应用程序。根据程序中的RDD动作和变换，Spark会创建一个运算图。
6. 当调用一个动作（如collect）时，图会被提交到一个有向无环图（DAG）调度程序。DAG调度程序将运算图划分成一些阶段。
7. 一个阶段由基于输入数据分区的任务组成。DAG调度程序会通过流水线把运算符连一起，从而优化运算图。例如，很多映射（map）运算符可以调度到一个阶段中。为种优化对Spark的性能是很关键的。DAG调度程序的最终结果是一组阶段。
8. 这些阶段会被传递到任务调度程序。任务调度程序通过集群管理器（Spark Srandalone/Yarn/Mesos）启动任务。任务调度器并不知道阶段之间的依赖性。
9. 任务在执行进程上运行，从而计算和保存结果。
10. 如果驱动进程的main退出，或者它调用了SparkContext.stop()，它就会终止执行进程并从集群管理器释放资源。