# 常见数据库引擎

* MyISAM
* InnoDB
* ISAM
  * 读取速度快，不占用大量内存和存储资源
  * 不运行事务，不容错，需经常备份实时数据
* MEMORY
  * 每个表可有32个索引，每个索引16列
  * 表中数据存储到内存中
* Archive
  * 为大量很少引用的历史，归档，或安全审计信息的存储和检索提供解决方案

# 如何设计一个关系型数据库

* RDBMS  
  * 程序实例
    * 存储管理
    * 缓存机制
    * SQL解析
    * 日志管理
    * 权限划分
    * 容灾机制
    * **索引管理**
    * **锁管理**
  * 存储（文件系统）
* 阶段
  * 需求分析阶段
    * 分析用户需求 
  * 概念设计阶段
    * 设计E-R图形

  * 逻辑设计阶段

      * 设计表格 
  * 物理设计阶段
    * 设计数据库的存储方式和存储路径 
  * 实现阶段 
  * 实施维护阶段

# 索引模块

## 索引的优点

* 避免全表扫描查找数据，提升查找效率
* 创建唯一性索引，保证数据库表中每行数据的唯一性
* 使用分组和排序子句进行数据检索时，减少查询中分组和排序时间
* 可在查询中使用优化隐藏器，提高系统性能

## 索引的缺点

* **创建**维护索引需要时间
* 索引占用物理**空间**，聚簇索引占用空间更大
* 当对表中数据增删改时，需**维护**索引

## 什么样的信息能成为索引？

* 主键，唯一键，普通键等让数据具备**一定区分性的字段**
* 什么情况下适合建立索引
  * 经常出现在关键字`order by` ,`group by `, `distinct` 后面的字段
  * union等集合操作的结果集字段
  * 经常查询的字段
  * 经常用作表连接的属性

## 索引的(类型)数据结构

* 二叉查找树
* B-Tree
  * 根节点至少包括两个孩子
  * 树中每个节点最多包含有m个孩子（m>=2）
  * 除根节点和叶节点外，其他每个节点至少有ceil(m/2)个孩子
  * 所有叶子节点都在同一层
* B+-Tree（Mysql）
  * 非叶子节点的子树指针与关键字个数相同
  * 非叶子节点的子树指针P[i],指向关键字值[K[i],K[i+1]]的子树
  * 非叶子节点仅用来索引，叶子节点存储数据
  * 所有叶子节点均有一个指针链接到下一个叶子节点
* Hash
  * 仅能满足“=”，“IN”，不能使用范围查询
  * 无法被用来避免数据的排序操作
  * 不能利用部分索引键查询
  * 不能避免表扫描
  * 遇到大量Hash值相等的情况后性能并不一定比B树索引高
* BitMap索引

## 密集索引和稀疏索引的区别

* 密集索引文件中的每个搜索码值都对应一个索引值
* 稀疏索引文件只为索引码的某些值建立索引项

## [聚簇索引和非聚簇索引的区别](https://blog.csdn.net/alexdamiao/article/details/51934917)

* InnoDB的B+树可能存储整行数据(聚簇索引),也可能存储主键的值(非聚簇索引)
* 聚簇索引查询只用一次,非聚簇索引需要回表查询多次,通过覆盖索引也可以只查询一次
* **覆盖索引**
  * 一个查询语句的执行只用从索引中就能够取得,不必从数据表中读取,称为实现了索引的覆盖,避免查到索引后回表操作,减少IO提高效率

## 回表

* 我们有个主键为ID的索引，和一个普通name字段的索引，我们在普通字段上搜索：

  `select * from table where name = '丙丙'`

  执行的流程是先查询到name索引上的“丙丙”，然后找到他的id是2，最后去主键索引，找到id为2对应的值。

  回到主键索引树搜索的过程，就是**回表**。不过也有方法避免回表，那就是**覆盖索引**。

## 覆盖索引

* 刚才我们是 select * ，查询所有的，我们如果只查询ID那，其实在Name字段的索引上就已经有了，那就不需要回表了。
* 覆盖索引可以减少树的搜索次数，提升性能，他也是我们在实际开发过程中经常用来优化查询效率的手段。
* 很多**联合索引**的建立，就是为了支持覆盖索引，特定的业务能极大的提升效率

## 联合索引

### 最左匹配原则

- mysql索引规则中要求复合索引要想使用第二个索引，必须先使用第一个索引。（而且第一个索引必须是等值匹配）。
- **列的排列顺序决定了可命中索引的列数**
- mysql会一直向右匹配直到遇到范围查询（>,<,between,like）就停止匹配
  - 比如a=3 and b=4 and c>5 and d=6 
  - 如果建立（a,b,c,d）顺序的索引，d是用不到索引的
  - 如果建立（a,b,d,c）的索引，则都可以用到，a,b,d的顺序可以任意调整。
  - =和in可以乱序，比如a=1 and b =2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会优化成索引可以识别的形式
- 当创建一个联合索引时,如(key1,key2,key3),相当于他建了(key1),(key1,key2),(key1,key2.key3)

### 索引失效

- 若条件中有or,即使其中有条件带索引也不会使用(尽量少使用or的原因)
- 对于多列索引,不是使用的第一部分,则不会使用索引
- like查询是以%开头
- 如果列类型是字符串,要在条件中使用绰号引起来,否则不会使用索引
- 如果MySQL估计使用全表扫描比索引快,则不使用索引

## 定位并优化慢查询Sql

* 根据慢日志定位慢查询sql
* 修改sql或者尽量让sql走索引
* 使用explain等工具分析sql
  * `type`表中找到所需行的方式
    * `ALL` `index` `range` `ref` `eq_ref` `const` `system` `NULL`
  * `key` 查询中实际使用的索引，若没有使用索引则为NULL
  * `ref` 表的连接匹配条件，即哪些列或常量被用于查找索引列上的值
  * `table` select查询的表的名字

## 查询优化器

* 一条SQL的查询可有不同执行方案,需通过优化器进行选择成本最低方案
  * 根据搜索条件,找出最有可能使用的索引
  * 计算全表扫描的代价
  * 计算使用不同索引执行查询的代价
  * 对比各种方案的代价,找出成本最低的



## 为何性别不适合用索引

* 访问索引需额外IO开销,从索引中拿到的只是地址,想访问真正的数据还需对表进行IO,此时开销并不一定比直接对表扫描小

# 锁模块

## MyISAM与InnoDB关于锁方面的区别是什么？

* MyISAM默认用的是表级锁，不支持行级锁
* InnoDB默认用的是行级锁，也支持表级锁
  * 走索引时，用行锁
  * 不走索引时，用表锁

## MyISAM适合的场景

* 频繁执行全表count
* 对数据进行增删改的频率不高，查询非常频繁
* 没有事务

## InnoDB适合的场景

* 数据增删改查频繁
* 可靠性要求比较高，要求支持事务

## 锁的分类

* 按锁的粒度

  * 表级锁
  * 行级锁
    * 锁加在数据行对应的索引上
  * 页级锁

* 按锁级别划分

  * 共享锁
  * 排它锁

* 按加锁方式划分

  * 自动锁

  * 显式锁

* 按操作划分

  * DML锁
  * DDL锁

* 按使用方式划分

  * 乐观锁
  * 悲观锁

### 乐观锁

* 通常乐观锁通过使用版本号/时间戳实现

  `update table set fields = #{fields},version=#{new_version} where id=#{id} and version = #{old_version}`

* 乐观锁与悲观锁不同的是，它是一种逻辑上的锁，而不需要数据库提供锁机制来支持

## 行锁

* 锁定的是索引记录而不是行数据，即锁定的是key

## GAP锁

* **防止幻读,在事务读取数据间隙上锁,防止在这个时间内其他事务修改数据**
* 根据检索条件向左寻找最靠近检索条件的记录A作为左区间，向右寻找最靠近检索条件的记录值B作为右区间，即锁定的间隙为（A，B）
  * 防止间隙内有新数据被插入
  * 防止已存在的数据更新成间隙内的数

## next-key锁（后码锁）

* gap锁与行锁的组合，InnoDB中，更新非唯一索引对应的记录时会加上Next-Key锁，如果更新记录为空则只能加gap锁

## [如何实现分布式锁](https://blog.csdn.net/weixin_33805152/article/details/93633536)

* 利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。

* **创建task_lock表，注意key作为唯一主键**

* ![表结构](https://img-blog.csdnimg.cn/20190625172056420.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zMzgwNTE1Mg==,size_16,color_FFFFFF,t_70)

  ```java
  //实现原理是:遍历表中的所有记录.筛选出过期的key,然后删除
  //每个小时第52分钟执行一次
      @Scheduled(cron = "0 52 * * * ?")
      private void checkSynTaskKeyIsExpire() {
          logger.info("=========开始检查数据库分布式锁的过期时间=======");
          List<TaskLock> taskLocks = taskLockMapper.findAll();
          //筛选出过期的key
          List<TaskLock> taskLockList = taskLocks.stream().
                  filter(taskLock -> new Date().getTime() - taskLock.getUtime().getTime()
                          - taskLock.getTimeout() * 1000 > 0).collect(Collectors.toList());
          taskLockList.forEach(taskLock -> {
              taskLockMapper.deleteByPrimaryKey(taskLock.getKey());
          });
          logger.info("=========trs_task_lock 删除{}条 过期的key=======",taskLockList.size());
      }
  
  ```

  

# 事务

## 为何要有事务

* 保证数据的最终一致性

## [事务的特性](https://blog.csdn.net/l1394049664/article/details/81814090)

* 原子性
  * 事务包含的操作要么全部成功,要么全部失败回滚,如果成功则必须完全应用到数据库,如果失败,则不能对数据库有任何影响
* 一致性
  * 事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态
  * 拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。
* 持久性
  * 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。
* 隔离性
  * 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
  * 对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。

## 如何保证事务的隔离性

* 加锁
* **频繁的加锁会带来什么问题**
  * 读数据的时候没办法修改。修改数据的时候没办法读取，极大的降低了数据库性能。
* **数据库是如何解决加锁后的性能问题的**
  * MVCC 多版本控制实现读取数据不用加锁， 可以让读取数据同时修改。修改数据时同时可读取。

## 事务隔离级别

* 可序列化
  * 最高隔离级别,强制事务串行执行,避免了幻读问题
  * 可序列化在读取的每一行数据上加锁,可能导致大量超时和锁争用问题
* 可重复读（默认）
  * **解决了脏读,不可重复读的发生**,保证多次读取同样记录结果是一样的,但无法解决幻读
  * 幻读:当某事务在读取某个范围内记录时,另一个事务又在该范围内插入了新的记录,当之前的事务再次读取该范围记录时,会产生幻行,通过多版本并发控制(MVCC)解决
* 提交读
  * 大多数数据库是默认提交读,MySQL不是
  * 一个事务从开始直到提交前,所做的任何修改对其他事务不可见,有时也叫不可重复读,因为两次查询的结果可能不同
  * **可避免脏读的发生**
* 未提交读
  * **事务可以读取未提交的数据(脏读**),实际中很少使用,任何情况都无法保证

## [事务隔离级别引起的问题](https://www.cnblogs.com/fjdingsd/p/5273008.html)

* 更新丢失
  
  * 两个事务对同一数据进行修改，后修改的覆盖先修改的
  
* 脏读
  
  * 事务1中修改数据未提交,被其他事务读到,然后事务1回滚,此时读的数据为脏数据
  
* 不可重复读
  
  * 指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了
  * 例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。
  
* 幻读
  
  * 第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。 同时，第二个事务也修改这个表中的数据，这种修改是向表中**插入一行新数据**。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象 发生了幻觉一样。
  
* **幻读和不可重复读都是读取了另一条已经提交的事务**（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。

* 关键语法

  * GROUP BY
    * 查询所有同学的学号，选课数，总成绩

  ```SQL
  select student_id,count(course_id),sum(score) 
  from score 
  group by student_id 
  ```

  * 查询所有同学的学号，姓名，选课数，总成绩

  ```sql
    select s.student_id,stu.name,count(s.course_id),sum(s.score) 
    from 
    	score s ,
    	student stu
    where s.student_id = stu.student_id
    group by s.student_id; 
  ```

* HAVING

  * 查询平均成绩大于60分的同学的学号和平均成绩

  ```sql
  select student_id,avg(score)
  from score
  group by student_id
  having avg(score)>60;
  ```

* 统计相关

  * COUNT
  * SUM
  * MAX
  * MIN
  * AVG

查询没有学全所有课的同学的学号，姓名

```sql
select stu.student_id,stu.name
from 
	student stu,
	score s
where stu.student_id = s.student_id
group by student_id
having count(*) <
(
    select count(*) from course
)
```

# 数据库范式

* 1NF
  * 每个属性都不可再分
* 2NF
  * 属性完全依赖于主键（消除部分子函数依赖）
* 3NF
  * 属性不依赖于其它非主属性（消除传递依赖）
* BCNF
  * 在1NF基础上，任何非主属性不能对主键子集依赖（在3NF基础上消除对主码子集的依赖）
* 4NF
  * 要求把同一表内的多对多关系删除
* 5NF
  * 从最终结构重新建立原始结构

# 数据库连接池原理

* 连接池的建立
  * 系统初始化时根据系统配置建立连接池，并在池中建立几个连接对象
  * Java中可使用Vector,Stack建立连接池
* 连接池管理
  * 客户请求数据库连接
    * 查看连接池中是否有空闲连接，若有则分配给客户；若无，则查看当前连接是否到最大连接数，若否则新建连接给客户；若是则按设定最大等待时间等待，若走出最大等待时间，则抛异常给客户
  * 当客户释放连接时
    * 判断连接引用次数是否超过规定值，若超过则从连接池中删除，否则保留
* 连接池关闭
  * 程序退出时，关闭连接池中所有连接，释放连接池相关资源

# 分库分表

* 概念
  * 分库
    * 用户id直接mod分成库的数目大小，将大库分成小库
  * 分表
    * 用户 id 直接 mod 分成表的数目大小， 将大表拆成小表
  * 分库分表
    * 方式1
      * 中间变量=`user_id %(分库数量*每个库的表数量)`
      * `库 = 取整数（中间变量/每个库的表数量）`
      * `表 = 中间变量 % 每个库的表数量`
    * 垂直切分
      * 单机的ACID被打破，数据到多机后，原来单机通过事务来进行处理逻辑会受很大影响
      * Join操作困难，因数据可能在两个数据库中了，不能方便利用数据库自身join
      * 靠外键进行约束的场景会受到影响
    * 水平切分
      * ACID被打破
      * Join操作受影响
      * 靠外键约束场景受影响
      * 依赖单库的自增序列生成唯一ID会受影响
      * 针对单个逻辑意义上的表的查询要跨库

## 如何解决分库分表带来的坏处

* ACID解决方法
  * 两阶段提交
    * 事务在第一阶段对资源进行准备，若在准备阶段有一个资源失败，那么在第二阶段的处理就是回滚所有资源，否则进行Commit操作
* 水平切分自增ID破坏
  * 将所有ID集中放在一个地方管理，对每个ID序列独立管理，每台机器使用ID时都从这个ID造成器上进行获取
* 跨库Join
  * 在应用层将原来数据库中Join操作分成多次数据库操作
  * 数据冗余
    * 将常用信息进行冗余，将原来需要Join的返回信息变为单表查询
  * 借助外部系统斛同跨库问题
    * 如搜索引擎
* 外键约束
  * 需要分库后的每个单库的数据是内聚的，否则就只能靠应用层的判断，容错方式

# 解决加锁后的性能问题:MVCC

* 概念

  * 同一份数据临时保留多版本的一种方式，进面实现并发控制

* 解决的问题

  * 同时读写数据库时，读数据的人会看到不一致数据

* 实现原理

  * 通过每行记录后面保存的两个隐藏的列实现，一个保存了行的删除时间，一个保存了系统版本号

  * 开始时系统版本号会作为事务版本号

  * INSERT - InnoDB为插入的每一行保存当前系统版本号作为行版本号。

    DELETE - InnoDB为删除的每一行保存当前系统版本号作为行删除标识。

    UPDATE - InnoDB为插入一行新纪录，保存当前系统版本号作为行版本号，同时，保存当前系统版本号到原来的行作为行删除标识。

* 优点

  * 保存两个额外系统版本号，使大多读操作都可以不用加锁，这样的设计使得读数据操作很简单

* 缺点

  * 每行记录都需要额外存储空间，需要做更多的行检查工作，以及额外的维护工作

## MVCC隔离级别

* MVCC是实现InnoDB存储引擎实现隔离级别的一种具体方式
* 提交读
* 可重复读

## 在读写并发过程中如何实现多版本

## 读写并发之后如何删除旧版本





