# Redis与Memcache的区别

* Memchache多线程，Redis单进程单线程
* Redis支持集群
* Redis数据类型丰富

# 为何Redis单线程这么快

* 纯内存操作
* 非阻塞的IO多路复用
* 单线程避免频繁上下文切换

# [Redis单进程单线程模型]([https://github.com/AobingJava/JavaFamily/blob/master/docs/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%81%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89%E3%80%81%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7.md](https://github.com/AobingJava/JavaFamily/blob/master/docs/redis/分布式锁、并发竞争、双写一致性.md))

* **Redis** 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是单线程的，所以 **Redis** 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 **Socket**，根据 **Socket** 上的事件来选择对应的事件处理器进行处理。
* 多个 **Socket** 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 **Socket**，会将 **Socket** 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

- 内存采用的是单进程单线程模型的KV数据库，QPS(每秒内查询次数) 10w
- Redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销。
- 多线程处理会涉及到锁，而且多线程处理会涉及到线程切换而消耗CPU。因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者网络带宽。单线程无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来解决。

# [Redis为何要使用IO多路复用]([https://wjqwsp.github.io/2018/03/25/redis-%E6%B5%85%E6%9E%90IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E4%B8%8E%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86/](https://wjqwsp.github.io/2018/03/25/redis-浅析IO多路复用与事件处理/))

* IO多路复用的本质是**同步阻塞IO(BIO)**，但是，它**最大的优势在于可以在一次阻塞中监听多个文件描述符**。我们代入Redis的场景，来分析一下为什么需要用到IO多路复用。

  * 需要处理多个客户端连接，最先想到的恐怕是用多个线程，每个线程处理一个连接。多线程的的存在必然需要昂贵的上下文切换，而且每个线程会有内存消耗，开销还是较大，如果只是要找出有事件到达的客户端，用多线程显然是得不偿失的。Redis本身就是单进程单线程的模式工作，多线程等待多个客户端显然与其系统思想不符。
  * **假如采用普通的同步阻塞IO，那么Redis可能会在一个客户端上长期阻塞。**该客户端可能长期没有数据到达，而Redis需要处理多个客户端的通信，当其他客户端有请求到达时，Redis则无法处理了，这显然是无法接受的。
  * **假如采用同步非阻塞IO，那么Redis的确可以不断地按顺序轮询所有客户端. 但很可能客户端是长期空闲的，这种反复地轮询会浪费大量的CPU资源。**

* **Redis需要的是可以单线程同时监听多个客户端，IO多路复用显然使其首选。**

* 优势

  * 采用多路复用技术可以让单个线程高效处理多个连接请求，（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快，即内存内的操作不会成为影响Redis性能的瓶颈
  * 系统开销小，系统不必创建进程/线程，也不必维护这些线程，大大减小了系统开销

  

# Redis特性

- 速度快
  - 因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
- 支持丰富数据类型
  - 支持string，list，set，sorted set，hash
- 支持事务
  - 操作都是原子性,因为其是单线程的
- 丰富的特性
  - 可用于缓存，消息，按key设置过期时间，过期后将会自动删除


# [Redis支持的数据类型]([https://github.com/AobingJava/JavaFamily/blob/master/docs/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%81%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89%E3%80%81%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7.md](https://github.com/AobingJava/JavaFamily/blob/master/docs/redis/分布式锁、并发竞争、双写一致性.md))

## string

* 最基本的数据类型，二进制安全的字符串，最大512M。

### String实现原理

- redis键值对中的key都是string类型的，redis底层是用C写的，对于String并没有直接使用C的字符数组，而是自己封装了一个sds类型

![img](https://img-blog.csdn.net/20170816140922843?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDkwMDc1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

- 为何需要新建数据类型？

  - C的字符串api是不安全，因为在使用字符数组后，需要跟踪内存的分配，在使用之前，需要预分配内存空间，否则会有缓冲区溢出，用完一个字符串，需要回收，否则会有内存泄漏
  - 将分配内存的事封装，不让调用方得知-->sds作用
  - 空间预分配，惰性回收
    - 每创建 一个新的String，不按实际大小分配，而是预分配更多内存。当字符串截断时，也不是立刻回收内存，而是减少len值，增加free值。字符串插入时，先看free够不够，不够再分配。这样减少了内存分配回收次数

- SDS与C字符串的区别

  ![img](https://img-blog.csdn.net/20170816141720909)

- SDS好处

  - 获取长度O（1）
  - 杜绝缓冲区溢出
  - 减少了字符串改变造成的空间分配次数

### String应用场景

* 共享用户session: **用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie**，但是可以利用**Redis**将用户的**Session**集中管理，在这种模式只需要保证**Redis**的高可用，每次用户**Session**的更新和获取都可以快速完成。大大提高效率。



## List

* 按照添加顺序保持顺序的字符串列表。

### List应用场景

  * 比如可以通过 **List** 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。
  * 比如可以通过 **lrange** 命令，读取某个闭区间内的元素，可以基于 **List** 实现分页查询，这个是很棒的一个功能，基于 **Redis** 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。
  * 比如可以搞个简单的消息队列，从 **List** 头怼进去，从 **List** 屁股那里弄出来。

## Set

* 无序的字符串集合，不存在重复的元素。

### Set应用场景

* 可以基于 **Set** 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。

## sorted set(zset)

* 去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

### zset应用场景

* 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

### [zset实现原理-跳跃表](https://segmentfault.com/a/1190000013418471)

- 跳跃表在增删改上与红黑树有相同的性能,是一种特殊的链表,链表的每个节点存了层信息,在查找节点时能跳过这些节点

- 跳跃表最低层(第一层)是一个拥有跳跃表所有节点的普通链表,每次往跳跃表插入链表节点时一定会插入到最低层,至于是否会插入最高层,由抛硬币决定

  ![img](https://i.loli.net/2020/07/24/i2w1gdWPLrSC6eT.png)

### zset为什么不用红黑树

- 优点
  - 实现比红黑树简单,比红黑树更容易扩展
  - 红黑树插入删除时为了平衡高度需要旋转附近节点,高并发时需要锁,跳表不用考虑
  - 一般zset操作是执行zrange之类的操作,取出连续节点,这些操作的缓存命中率比红黑树高
- 缺点
  - 占用更多内存,每个节点大小取决于该节点层数
  - 空间局部性较差导致缓存命中率较低

## Hash

* key-value对的一种集合。

* 这个是类似 **Map** 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是**这个对象没嵌套其他的对象**）给缓存在 **Redis** 里，然后每次读写缓存的时候，可以就操作 **Hash** 里的**某个字段**。

  但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。

![img](https://i.loli.net/2020/07/26/hFSnPkrUAdg8D3j.jpg)



# 从海量Key里查询某一固定前缀的Key

**使用keys对线上的业务的影响**

  * KEYS pattern

    `keys k1*`

    * 查询所有符合给定模式pattern的key

    * KEYS指令一次性返回所有匹配的key

    * 键的数量过大会造成服务器卡顿

* SCAN cursor

   `scan 0 match k1* count 10  `  

   *  基于游标的迭代器,需要基于上一次的游标延续之前的迭代过程
   *  以0作为粮票开始一次新的迭代,直到命令返回游标0完成一次遍历
   *  不保证每次执行都返回某个给定数量的元素,支持模糊查询
   *  一次返回的数量不可控.只能是大概率符合count参数

# [Redis 怎么实现分布式锁？](https://www.cnblogs.com/zhili/p/redisdistributelock.html)

[教程2](https://juejin.im/post/5b16148a518825136137c8db)

* 分布式锁需要解决的问题
  * 互斥性
  * 安全性
  * 死锁
  * 容错

## 加锁的错误方式1

* `SETNX key value`和`expire key seconds`
  
  * setnx 和expire是2条redis指令,不具备原子性,若程序崩溃,则不会释放锁
  
  ```java
  public static void wrongGetLock1(Jedis jedis, String lockKey, String requestId, int expireTime) {
          Long result = jedis.setnx(lockKey, requestId);
          if (result == 1) {
              // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁
              jedis.expire(lockKey, expireTime);
          }
      }
  ```

## 加锁的错误方式2

* 客户端自己生成过期时间,强制要求分布式环境下所有客户端的时间必须同步
* 当锁,如果多个客户端同时执行jedis.getSet()方法,虽只有一个客户端是加锁的,但这个客户端的锁的过期时间可能被其他客户端覆盖,不具备加锁和解锁必须是同一客户端的特性
  * **解决上面这段代码的方式就是为每个客户端加锁添加一个唯一标示，已确保加锁和解锁操作是来自同一个客户端。**

``` java
 public static boolean wrongGetLock2(Jedis jedis, String lockKey, int expireTime) {
        long expires = System.currentTimeMillis() + expireTime;
        String expiresStr = String.valueOf(expires);
        // 如果当前锁不存在，返回加锁成功
        if (jedis.setnx(lockKey, expiresStr) == 1) {
            return true;
        }

        // 如果锁存在，获取锁的过期时间
        String currentValueStr = jedis.get(lockKey);
        if (currentValueStr != null && Long.parseLong(currentValueStr) < System.currentTimeMillis()) {
            // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间
            String oldValueStr = jedis.getSet(lockKey, expiresStr);
            if (oldValueStr != null && oldValueStr.equals(currentValueStr)) {
                // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才有权利加锁
                return true;
            }
        }
        // 其他情况，一律返回加锁失败
        return false;
    }
```

## 解锁的错误方式1

* 这种不先判断拥有者而直接解锁的方式，会导致任何客户端都可以随时解锁。即使这把锁不是它上锁的。

* ```java
   public static void wrongReleaseLock1(Jedis jedis, String lockKey) {
          jedis.del(lockKey);
      }
  ```

## 解锁的错误方式2

* 判断和删除不是一个原子性操作。在并发的时候很可能发生解除了别的客户端加的锁。

  * 客户端A加锁，一段时间之后客户端A进行解锁操作时，在执行jedis.del()之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del方法，则客户端A将客户端B的锁给解除了。从而不也不满足加锁和解锁必须是同一个客户端特性。
  * **解决思路就是需要保证GET和DEL操作在一个事务中进行，保证其原子性。**

* ```java
  public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) {
  
          // 判断加锁与解锁是不是同一个客户端
          if (requestId.equals(jedis.get(lockKey))) {
              // 若在此时，这把锁突然不是这个客户端的，则会误解锁
              jedis.del(lockKey);
          }
  
  ```

## 加锁正确方式

```redis
SET key value [EX seconds] [PX milliseconds] [NX|XX]
```

* 参数

  * EX second 

    * 设置键的过期时间为second秒

  * PX millisecond

    * 设置键的过期时间为millisecond 毫秒

  * NX

    * 只在键不存在时,才对键进行设置操作

  * XX

    * 只在键已经存在时,才对键进行设置操作

  * SET操作成功完成时,返回OK,否则返回nil

> set locktarget 12345 ex 10 nx

* 要点

  * value要具有唯一性
  * 释放锁时要验证value值,不能误解锁

* 缺点

  * 加锁时只作用在一个Redis节点上

  * 如果这个master节点发生了主从切换,那么会有锁丢失的情况

    * 在Redis的master节点上拿到了锁,但这个加锁的key还没有同步到slave节点
    * master故障,发生故障转移,slave节点升级为master节点,导致锁丢失

## [分布式锁续期](https://juejin.im/post/5bf3f15851882526a643e207)

如果在公司里落地生产环境用分布式锁的时候，一定是会用开源类库的，比如Redis分布式锁，一般就是用**Redisson**框架就好了，非常的简便易用。

* 默认情况下加锁时间30s，若业务未执行完锁到20s时，会进行一次续期，锁重置为30s
* 若超过30s，客户端还想持有这把锁怎么办
  * 客户端一旦加锁成功。就会启动一个watch dog看门狗，是一个后台线程，每隔10s检查一下，如客户端还持有锁key,就不断延长key生存时间

# [Redis内存回收原理](https://leetcode-cn.com/circle/article/ztZkJJ/)

* 围绕两个方面
  * Redis过期策略
    * 删除过期时间的key值
  * Redis 淘汰策略
    * 内存使用 达到maxmemory上限触发内存淘汰数据
    * 内存淘汰策略用于处理内存不足时的需要申请额外空间的数据.内存淘汰策略的选取并不会影响过期的key的处理,过期策略用于处理过期的缓存数据

## Redis过期策略

* 定时过期
  * 每个设置过期时间的key都要创建一个定时器,到过期时间立即删除,该策略可以立即删除过期的数据,对内存很友好;但会占用大量CPU资源去处理过期数据,从而降低缓存响应时间和吞吐量
* 惰性过期(惰性删除)
  * 当获取某key时，检查是否过期，过期删除且不返回任何东西.对内存不友好,极端情况可能出现大量的过期key没有被再次访问
* 定期过期(定期删除)
  * 每隔一定时间(默认100ms),会扫描一定数量的数据库expires字典中一定数量的key,并其中已过期的key

### 大量的key同时过期的注意事项

* 集中过期, 由于清除大量的key很耗时,会出现短暂的卡顿现象
* 解决
  * 在设置key过期时间的时候,给每个key的**过期时间加上随机值**,使时间分散

## Redis内存淘汰策略

当内存使用达到maxmemory极限时,需要使用LRU淘汰算法来决定清理掉哪些数据,以保证新数据的存入

* volatile-lru 
  * 从**设置过期时间的数据**集中挑选出最近最少使用
* volatile-ttl
  * 从**设置过期时间数据**中选将要过期数据
* volatile-random
  * 从**已设置过期时间数据**中选任意数据
* allkeys-lru
  * 从**所有数据集**中选最近最少使用
* allkeys-random
  * 从**所有数据集**中任意选数据
* noeviction
  * 禁止驱逐数据

# 如何使用Redis做异步队列?

* **使用List作为队列,RPUSH生产消息,LPOP消费消息**
  * 缺点
    * 没有等待队列里有值就直接消费
  * 弥补
    * 可以通过在应用层引用Sleep机制去调用LPOP重试

* `BLPOP key [key ...] timeout` :阻塞直到队列有消息或者超时

  ```redis
  blpop testlist 30   //30秒内一直等待
  ```

  * 缺点
    * 只能供一个消费者消费

* pub/sub:主题订阅者模式

  * 发送者(pub)发送消息,订阅者(sub接收消息)

  * 订阅者可以订阅任意数量的频道(topic)

    * `publish myTopic "Hello"`

    * `subscribe myTopic`

  * 缺点

    * 消息的发布是无状态的,无法保证可达

# [Redis如何做持久化](https://juejin.im/post/5b70dfcf518825610f1f5c16)

* RDB(快照)持久化
  * 保存某个时间点的全量数据快照
  * SAVE
    * **会阻塞当前Redis服务器，直到持久化完成**，线上应该禁止使用。
  * BGSAVE
    * 该触发方式会fork一个子进程，由子进程负责持久化过程，因此**阻塞只会发生在fork子进程的时候**。
  * 缺点
    * 内存数据的全量同步,数据量大会由于I/O而严重影响性能
    * 可能会因为Redis挂掉而丢失从当前至最近一次快照期间的数据
  * 自动触发RDB持久化的方式
    * 根据redis.conf配置里的SAVE m n 定时触发(用的是BGSAVE)
    * **主从复制时,主节点自动触发**
    * 执行Debug Reload
    * 执行Shutdown且没有开启AOF
* AOF(Append-Only-File)持久化:保存写状态
  * 记录下除了查询以外的所有变更数据库状态的指令
  * 以append的形式追加保存到AOF文件(增量)
  * **手动触发：** `bgrewriteaof`，**自动触发** 就是根据配置规则来触发，当然自动触发的整体时间还跟Redis的定时任务频率有关系。
* RDB-AOF混合持久化方式
  * BGSAVE做镜像全量持久化,AOF做增量持久化

## 日志重写解决AOF文件大小不断增大的问题

* AOF重写机制
  * 调用fork(),创建一个子进程(重写子进程)
  * 子进程读取现有AOF文件,将指令分析压缩并写入临时文件中
  * 主进程持续将新的变动同时写到内存和原来的AOF里,以保证原有AOF可用性
  * 主进程获取子进程重写AOF的完成信号,往新AOF同步增量变动
  * 使用新的AOF文件替换掉旧的AOF文件



# [Redis一致性哈希算法](https://zhuanlan.zhihu.com/p/34985026)

## 为什么要对redis集群使用hash

* 假设有一个社交网站,需要用Redis存储图片资源,存储格式为键值对,key为图片名称,value为该图片所在文件服务器的路径,我们需要根据文件名查找路径.由于规则是随机的,我们不确定图片在哪个服务器上,使用Hash比较好

## 为何要有一致性Hash算法

* 在传统的哈希表中，添加或删除一个槽位，几乎需要对所有关键字进行重新映射(增加删除服务器时,需重新hash)
  * 算法使用节点数取余，强依赖node数，当node数发生变化时，数据需要迁移
* 一致性Hash将整个hash值空间组织成一个虚拟的圆环（2^32）
* 将服务器使用Hash（ip或主机名为关键字）进行哈希，确定在环上的位置
* 将数据key使用相同的函数hash计算出哈希值，并确定此数据在环上的位置，从此位置顺时针走，遇到第一台服务器，就是其位置.如果增加一台服务器,则受影响的是新服务器到该环的前一台服务器,需重新定位之间的一小部分服务器位置

## 一致性Hash算法缺点及解决方案

* 不足
  
  * 在服务结点太少时，容易因节点分布不均而造成数据倾斜,大量数据会集中在长度较大的环上
  
* 解决
  
  ​	![img](https://pic3.zhimg.com/80/v2-0368841e5020dd07f1e67f449b49a1ba_720w.jpg)
  
  * 引入虚节点，对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点
  * 数据定位算法不变，只是多了虚节点到实际结点的映射,以达到数据平均分配的目的
  * 在实际应用中，通常将虚节点数设置为32甚至更大

# Redis数据的恢复

RDB和AOF文件共存情况下的恢复流程

* 检查是否有AOF文件
  * 若存在,则使用AOF文件
  * 否则,使用RDB文件

RDB和AOF的优缺点

* RDB优点
  * 全量数据快照,文件小,恢复快
* RDB缺点
  * 无法保存最近一次快照之后的数据
* AOF优点
  * 可读性高,适合保存增量数据,数据不易丢失
* AOF缺点
  * 文件体积大,恢复时间长

# [Redis的主从同步机制](https://github.com/AobingJava/JavaFamily/blob/master/docs/redis/集群高可用、哨兵、持久化、LRU.md)

* 启动一台slave 的时候，他会发送一个**psync**命令给master ，如果是这个**slave第一次连接到master，他会触发一个全量复制**。master就会启动一个线程，生成**RDB**快照，还会把新的写请求都缓存在内存中，**RDB**文件生成后，master会将这个**RDB**发送给slave的，slave拿到之后做的第一件事情就是写进本地的磁盘，然后加载进内存，然后master会把内存里面缓存的那些新命令都发给slave。
  * 数据传输的时候断网了或者服务器挂了怎么办
    * 传输过程中有什么网络问题啥的，会自动重连的，并且连接之后会把缺少的数据补上的。

* 在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。

* [全同步过程](https://www.cnblogs.com/kismetv/p/9236731.html)
  * Slave发送sync命令到Master
  * Master启动一个后台进程,将Redis中的数据快照保存到文件中
  * Master将保存数据快照期间接收到的写命令缓存起来
  * Master完成写文件操作后,将该文件发送给Slave
  * 使用新的AOF文件替换旧的AOF文件
  * Master 将这期间收集的增量写命令发送给Slave端
* [部分复制](https://www.cnblogs.com/kismetv/p/9236731.html)
  * **由于全量复制在主节点数据量较大时效率太低**，因此Redis2.8开始提供部分复制，**用于处理网络中断时的数据同步**。
  * 复制偏移量
    * 主节点和从节点分别维护一个复制偏移量（offset），代表的是**主节点向从节点传递的字节数**；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。
    * **offset用于判断主从节点的数据库状态是否一致**：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。
  * 复制积压缓冲区
    * 复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，**无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区**。
    * 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，**当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制**
    * 从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：
      - 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；
      - **如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制**。
  * 服务器运行ID(runid)
    * 主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；**当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制**：
      - 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；
      - 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。

# [缓存引发的问题](https://blog.csdn.net/zeb_perfect/article/details/54135506)

## 缓存雪崩

* 设置缓存时采用了相同的过期时间,导致缓存在某一时刻同时失效,请求全部转发到DB,DB瞬时压力过大雪崩
* 解决
  * 加锁或队列的方式保证缓存的单线程写,从而避免失效时大量的并发请求落到底层存储系统上
  * 在原有失效时间上加一个随机值,比如1-5分钟随机,这样缓存时间重复率就会降低,很难引发集体失效事件

## 缓存击穿

* 对一些设置了过期时间的key,如果这些key(热点数据)可能会在某些时间被超高并发地访问,与缓存雪崩的区别是这里针对某一key,前者是很多key
* 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
* 解决
  * 使用互斥锁(mutex key)
    * 在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）**去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存**；否则，就重试整个get缓存的方法。

## 缓存穿透

* 查询一个一定不存在的数据,**由于缓存是不命中时被动写的**，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。
* 解决
  * 如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
  * 使用**布隆过滤器**

### [布隆过滤器(Bloom Filter)](https://juejin.im/post/5db69365518825645656c0de)

[**布隆过滤器的本质实际上是 “位(bit)数组”，也就是说每一个存入布隆过滤器的数据都只占一位。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。**](https://mp.weixin.qq.com/s/-DZj158-LOQmnCayf1_n3A)

**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

* 原理
  * 当一个元素被加入集合时，**通过K个散列函数**将这个元素映射成一个位数组中的K个点，把它们置为1。

  * 检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：

    * 如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。

    ![img](https://user-gold-cdn.xitu.io/2019/10/28/16e112fbd031fe71?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

* 缺点

  * bloom filter之所以能做到在时间和空间上的效率比较高，是因为牺牲了判断的准确率、删除的便利性
    * 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。
    * 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用[Counting Bloom Filter](http://wiki.corp.qunar.com/confluence/download/attachments/199003276/US9740797.pdf?version=1&modificationDate=1526538500000&api=v2)
  
  

# [缓存和数据库一致性]([https://github.com/AobingJava/JavaFamily/blob/master/docs/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%81%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89%E3%80%81%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7.md](https://github.com/AobingJava/JavaFamily/blob/master/docs/redis/分布式锁、并发竞争、双写一致性.md))

* 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。

* 更新的时候，**先更新数据库，然后再删除缓存**。

  * 如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**

    其实删除缓存，而不是更新缓存，就是一个 Lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

* **采用延时双删策略**

  * 在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。(只能保证最终一致性,无法保证实时一致性)

    ```java
    public void write( String key, Object data )
    {
        //先删除缓存
    	redis.delKey( key );
        //再写数据库
    	db.updateData( data );
        //休眠500毫秒
    	Thread.sleep( 500 );
        //再次删除缓存
    	redis.delKey( key );
    }
    ```

* **异步更新缓存(基于订阅binlog的同步机制)**

  * **读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。**
  * 一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。

# Redis集群高可用

* 哨兵集群**sentinel**,哨兵必须用三个实例去保证自己的健壮性的，哨兵+主从并**不能保证数据不丢失**，但是可以保证集群的**高可用**

  ![img](https://camo.githubusercontent.com/15f2ac7d26b5fe90069a405529a099ba672bb753/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f30303679386d4e366c793167387039676a337179616a333039333039707765692e6a7067)

* 哨兵组件的主要功能：

  * 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。
  * 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
  * 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
  * 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。

# Redis key设计

* 表名:列名:主键名:主键值

# [Redis缓存预热](https://blog.csdn.net/baomw/article/details/89182777)

# [Redis并发竞争key](https://juejin.im/post/5ce0f30a6fb9a07eaf2b6108)

* 并发指的是多个redis的client同时set key引起的并发问题。

* 解决方案1:**分布式锁+时间戳**

  * **用SETNX实现分布式锁**

  * **时间戳**

    * 由于上面举的例子，要求key的操作需要顺序执行，所以需要保存一个时间戳判断set顺序。

    ```
    系统A key1 {ValueA 7:00}
    系统B key1 { ValueB 7:05}
    ```

    ​	假设系统B先抢到锁，将key1设置为{ValueB 7:05}。接下来系	统A抢到锁，发现自己的key1的时间戳早于缓存中的时间戳	（7:00<7:05），那就不做set操作了。

* 解决方案2:**利用消息队列**(通用操作)

  * 在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。
  * 把Redis.set操作放在队列中使其串行化,必须的一个一个执行。